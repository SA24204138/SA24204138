---
title: "Introduction to SA24204138"
author: "SA24204138"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{De-biased Sparse PCA}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

本r包的方法来自于论文De-Biased Sparse PCA: Inference for Eigenstructure of Large Covariance Matrices。文章的主要工作是在稀疏条件下对于特征结构的的渐近正态估计。对于回归问题

$$
\min_{\beta} \| Y - X\beta \|^2 + \lambda \|\beta\|_1
$$
参数$$\beta$$在l2范数下以

$$
\| \beta - \beta^* \|_2 = O\left( \sqrt{\frac{\log p}{n}} \right)
$$
的速度收敛。该估计器存在渐近偏差，因此论文研究了样本的特征结构，从而识别了偏差项，得到去偏估计器。本r包正是基于其所证明的去偏估计以及论文中的伪代码所编写的r包。论文把算法分为两个部分，一个部分是根据误差的黑塞矩阵，使用nodewise lasso的方法来估计约束条件

$$（\lambda,T）：$$
$$
f(\gamma_j) := \Gamma_j^T A \Gamma_j + \lambda_j \|\gamma_j\|_1\quad\{\gamma_j \in \mathbb{R}^{p-1} : \|\gamma_j\|_1 \leq T_j \}.
$$
矩阵A初始是任意矩阵，而在迭代过程中会替换为下面的式子


$$
R_n(\hat{\beta}) = -\Sigma + \|\hat{\beta}\|_2^2 I + 2 \hat{\beta} \hat{\beta}^T,
$$
然后求解方程的稳定点：


$$
f(\beta)=-1/2\beta^t\hat{\Sigma}\beta+\| \beta \|_2^4+\lambda\| \beta \|_1 \quad\ {\{\beta \in B: 
\|\beta \|_1<T}\}
      
$$
这个公式其实来源于这个式子，加上一个惩罚项

$$R(\beta) := \frac{1}{4} \|\Sigma_0 - \beta \beta^T\|_F^2 
= \frac{1}{4} \operatorname{tr}(\Sigma_0^2) - \frac{1}{2} \beta^T \Sigma_0 \beta + \frac{1}{4} \|\beta\|_2^4.$$


随后计算出


$$
R_n(\hat{\beta}) = -\Sigma + \|\hat{\beta}\|_2^2 I + 2 \hat{\beta} \hat{\beta}^T,
$$
这个式子随后会进入到迭代中当作矩阵A,计算约束，下面的是迭代的结果


$$
\hat{b} := \hat{\beta} - \Theta^T \left( \|\hat{\beta}\|_2^2 \hat{\beta} - \Sigma \hat{\beta} \right),
$$
这个是de-biased estimator和下面这个式子


$$
\hat{\Lambda} := \|\hat{\beta}\|_2^2 - 2 \hat{\beta}^T \Theta^T \left( \|\hat{\beta}\|_2^2 \hat{\beta} - \Sigma \hat{\beta} \right).
$$
这个是eigenvalue estimator

初始变量：论文中对于矩阵A的初始设定是任意矩阵，但是对于$$\beta$$的初始值设定是由严格要求的。因为在高维情况下，对于损失函数$$R(\beta)$$是非凸的函数，所以需要$$\beta$$初始值的选取离$$\beta_0$$的真实值比较近，论文中是选择合适的$$\eta$$使得$$\beta \in R^P:\quad\|\beta-\beta_0\|_2\leq\eta$$.

这个包的输入值为
X, #样本矩阵
beta_hat, #beta的初始值
lambda, #lambda的初始值
T,#T的初始值
max_iter  #最大迭代次数
tol = #收敛阈值

```{}
#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::plugins(cpp11)]]
using namespace Rcpp;
//' @useDynLib SA24204138

// Soft-thresholding function
double soft_threshold(double x, double lambda) {
  if (x > lambda) return x - lambda;
  if (x < -lambda) return x + lambda;
  return 0.0;
}

// Optimize principal component vector
arma::vec optimize_beta(const arma::mat& Sigma_hat, arma::vec beta, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  int p = Sigma_hat.n_cols;
  arma::vec beta_old = beta;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    for (int j = 0; j < p; ++j) {
      double partial_residual = -arma::dot(Sigma_hat.row(j).t(), beta) + Sigma_hat(j, j) * beta(j);
      beta(j) = soft_threshold(partial_residual, lambda) / Sigma_hat(j, j);
    }
    // Enforce L1 norm constraint
    if (arma::norm(beta, 1) > T) {
      beta *= T / arma::norm(beta, 1);
    }
    // Convergence check
    if (arma::norm(beta - beta_old, 2) < tol) break;
    beta_old = beta;
  }
  return beta;
}

// Nodewise Lasso function
arma::mat nodewise_lasso(const arma::mat& A, double lambda, double T) {
  int p = A.n_cols;
  arma::mat Theta = arma::zeros<arma::mat>(p, p);
  
  for (int j = 0; j < p; ++j) {
    arma::vec gamma = arma::zeros<arma::vec>(p - 1);
    arma::vec Aj = A.col(j);
    arma::mat A_minus_j = A;
    A_minus_j.shed_col(j);
    
    double error_tolerance = 1e-6;
    arma::vec gamma_old = gamma;
    double error = 1.0;
    int max_iter = 1000;
    int iter = 0;
    
    while (error > error_tolerance && iter < max_iter) {
      for (int k = 0; k < gamma.n_elem; ++k) {
        double partial_residual = Aj(k) - arma::dot(A_minus_j.row(k).t(), gamma);
        gamma(k) = soft_threshold(partial_residual, lambda) / (A_minus_j(k, k) + 1e-10);
      }
      error = arma::norm(gamma - gamma_old, 2);
      gamma_old = gamma;
      iter++;
    }
    Theta.col(j) = -arma::join_cols(gamma.head(j), arma::vec(1, arma::fill::zeros), gamma.tail(p - j - 1));
  }
  return Theta;
}

// Debiased sparse PCA function
List debiased_sparse_pca(const arma::mat& Sigma_hat, const arma::vec& beta_hat, double lambda, double T, const arma::mat& Theta) {
  double beta_hat_norm_sq = arma::dot(beta_hat, beta_hat);
  arma::vec bias_correction = Theta * (beta_hat_norm_sq * beta_hat - Sigma_hat * beta_hat);
  arma::vec beta_debiased = beta_hat - bias_correction;
  
  double eigenvalue = arma::dot(beta_hat, Sigma_hat * beta_hat);
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue
  );
}

// Alternating optimization main function
// [[Rcpp::export]]
List alternating_debiased_sparse_pca(const arma::mat& X, arma::vec beta_hat, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  if (X.n_rows < X.n_cols) {
    stop("Input matrix X should have more rows than columns.");
  }
  
  int p = X.n_cols;
  arma::mat Sigma_hat = X.t() * X / X.n_rows;
  beta_hat = optimize_beta(Sigma_hat, beta_hat, lambda, T);
  arma::mat Theta;
  arma::vec beta_debiased;
  double eigenvalue;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    arma::mat Rn_beta = -Sigma_hat + arma::eye<arma::mat>(p, p) * arma::dot(beta_hat, beta_hat) + 2 * beta_hat * beta_hat.t();
    Theta = nodewise_lasso(Rn_beta, lambda, T);
    
    List pca_result = debiased_sparse_pca(Sigma_hat, beta_hat, lambda, T, Theta);
    beta_debiased = as<arma::vec>(pca_result["beta_debiased"]);
    eigenvalue = as<double>(pca_result["eigenvalue"]);
    
    if (arma::norm(beta_debiased - beta_hat, 2) < tol) break;
    beta_hat = beta_debiased;
  }
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue,
    Named("Theta") = Theta
  );
}

#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::plugins(cpp11)]]
using namespace Rcpp;
//' @useDynLib SA24204138

// Soft-thresholding function
double soft_threshold(double x, double lambda) {
  if (x > lambda) return x - lambda;
  if (x < -lambda) return x + lambda;
  return 0.0;
}

// Optimize principal component vector
arma::vec optimize_beta(const arma::mat& Sigma_hat, arma::vec beta, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  int p = Sigma_hat.n_cols;
  arma::vec beta_old = beta;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    for (int j = 0; j < p; ++j) {
      double partial_residual = -arma::dot(Sigma_hat.row(j).t(), beta) + Sigma_hat(j, j) * beta(j);
      beta(j) = soft_threshold(partial_residual, lambda) / Sigma_hat(j, j);
    }
    // Enforce L1 norm constraint
    if (arma::norm(beta, 1) > T) {
      beta *= T / arma::norm(beta, 1);
    }
    // Convergence check
    if (arma::norm(beta - beta_old, 2) < tol) break;
    beta_old = beta;
  }
  return beta;
}

// Nodewise Lasso function
arma::mat nodewise_lasso(const arma::mat& A, double lambda, double T) {
  int p = A.n_cols;
  arma::mat Theta = arma::zeros<arma::mat>(p, p);
  
  for (int j = 0; j < p; ++j) {
    arma::vec gamma = arma::zeros<arma::vec>(p - 1);
    arma::vec Aj = A.col(j);
    arma::mat A_minus_j = A;
    A_minus_j.shed_col(j);
    
    double error_tolerance = 1e-6;
    arma::vec gamma_old = gamma;
    double error = 1.0;
    int max_iter = 1000;
    int iter = 0;
    
    while (error > error_tolerance && iter < max_iter) {
      for (int k = 0; k < gamma.n_elem; ++k) {
        double partial_residual = Aj(k) - arma::dot(A_minus_j.row(k).t(), gamma);
        gamma(k) = soft_threshold(partial_residual, lambda) / (A_minus_j(k, k) + 1e-10);
      }
      error = arma::norm(gamma - gamma_old, 2);
      gamma_old = gamma;
      iter++;
    }
    Theta.col(j) = -arma::join_cols(gamma.head(j), arma::vec(1, arma::fill::zeros), gamma.tail(p - j - 1));
  }
  return Theta;
}

// Debiased sparse PCA function
List debiased_sparse_pca(const arma::mat& Sigma_hat, const arma::vec& beta_hat, double lambda, double T, const arma::mat& Theta) {
  double beta_hat_norm_sq = arma::dot(beta_hat, beta_hat);
  arma::vec bias_correction = Theta * (beta_hat_norm_sq * beta_hat - Sigma_hat * beta_hat);
  arma::vec beta_debiased = beta_hat - bias_correction;
  
  double eigenvalue = arma::dot(beta_hat, Sigma_hat * beta_hat);
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue
  );
}

// Alternating optimization main function
// [[Rcpp::export]]
List alternating_debiased_sparse_pca(const arma::mat& X, arma::vec beta_hat, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  if (X.n_rows < X.n_cols) {
    stop("Input matrix X should have more rows than columns.");
  }
  
  int p = X.n_cols;
  arma::mat Sigma_hat = X.t() * X / X.n_rows;
  beta_hat = optimize_beta(Sigma_hat, beta_hat, lambda, T);
  arma::mat Theta;
  arma::vec beta_debiased;
  double eigenvalue;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    arma::mat Rn_beta = -Sigma_hat + arma::eye<arma::mat>(p, p) * arma::dot(beta_hat, beta_hat) + 2 * beta_hat * beta_hat.t();
    Theta = nodewise_lasso(Rn_beta, lambda, T);
    
    List pca_result = debiased_sparse_pca(Sigma_hat, beta_hat, lambda, T, Theta);
    beta_debiased = as<arma::vec>(pca_result["beta_debiased"]);
    eigenvalue = as<double>(pca_result["eigenvalue"]);
    
    if (arma::norm(beta_debiased - beta_hat, 2) < tol) break;
    beta_hat = beta_debiased;
  }
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue,
    Named("Theta") = Theta
  );
}


#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::plugins(cpp11)]]
using namespace Rcpp;
//' @useDynLib SA24204138

// Soft-thresholding function
double soft_threshold(double x, double lambda) {
  if (x > lambda) return x - lambda;
  if (x < -lambda) return x + lambda;
  return 0.0;
}

// Optimize principal component vector
arma::vec optimize_beta(const arma::mat& Sigma_hat, arma::vec beta, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  int p = Sigma_hat.n_cols;
  arma::vec beta_old = beta;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    for (int j = 0; j < p; ++j) {
      double partial_residual = -arma::dot(Sigma_hat.row(j).t(), beta) + Sigma_hat(j, j) * beta(j);
      beta(j) = soft_threshold(partial_residual, lambda) / Sigma_hat(j, j);
    }
    // Enforce L1 norm constraint
    if (arma::norm(beta, 1) > T) {
      beta *= T / arma::norm(beta, 1);
    }
    // Convergence check
    if (arma::norm(beta - beta_old, 2) < tol) break;
    beta_old = beta;
  }
  return beta;
}

// Nodewise Lasso function
arma::mat nodewise_lasso(const arma::mat& A, double lambda, double T) {
  int p = A.n_cols;
  arma::mat Theta = arma::zeros<arma::mat>(p, p);
  
  for (int j = 0; j < p; ++j) {
    arma::vec gamma = arma::zeros<arma::vec>(p - 1);
    arma::vec Aj = A.col(j);
    arma::mat A_minus_j = A;
    A_minus_j.shed_col(j);
    
    double error_tolerance = 1e-6;
    arma::vec gamma_old = gamma;
    double error = 1.0;
    int max_iter = 1000;
    int iter = 0;
    
    while (error > error_tolerance && iter < max_iter) {
      for (int k = 0; k < gamma.n_elem; ++k) {
        double partial_residual = Aj(k) - arma::dot(A_minus_j.row(k).t(), gamma);
        gamma(k) = soft_threshold(partial_residual, lambda) / (A_minus_j(k, k) + 1e-10);
      }
      error = arma::norm(gamma - gamma_old, 2);
      gamma_old = gamma;
      iter++;
    }
    Theta.col(j) = -arma::join_cols(gamma.head(j), arma::vec(1, arma::fill::zeros), gamma.tail(p - j - 1));
  }
  return Theta;
}

// Debiased sparse PCA function
List debiased_sparse_pca(const arma::mat& Sigma_hat, const arma::vec& beta_hat, double lambda, double T, const arma::mat& Theta) {
  double beta_hat_norm_sq = arma::dot(beta_hat, beta_hat);
  arma::vec bias_correction = Theta * (beta_hat_norm_sq * beta_hat - Sigma_hat * beta_hat);
  arma::vec beta_debiased = beta_hat - bias_correction;
  
  double eigenvalue = arma::dot(beta_hat, Sigma_hat * beta_hat);
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue
  );
}

// Alternating optimization main function
// [[Rcpp::export]]
List alternating_debiased_sparse_pca(const arma::mat& X, arma::vec beta_hat, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  if (X.n_rows < X.n_cols) {
    stop("Input matrix X should have more rows than columns.");
  }
  
  int p = X.n_cols;
  arma::mat Sigma_hat = X.t() * X / X.n_rows;
  beta_hat = optimize_beta(Sigma_hat, beta_hat, lambda, T);
  arma::mat Theta;
  arma::vec beta_debiased;
  double eigenvalue;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    arma::mat Rn_beta = -Sigma_hat + arma::eye<arma::mat>(p, p) * arma::dot(beta_hat, beta_hat) + 2 * beta_hat * beta_hat.t();
    Theta = nodewise_lasso(Rn_beta, lambda, T);
    
    List pca_result = debiased_sparse_pca(Sigma_hat, beta_hat, lambda, T, Theta);
    beta_debiased = as<arma::vec>(pca_result["beta_debiased"]);
    eigenvalue = as<double>(pca_result["eigenvalue"]);
    
    if (arma::norm(beta_debiased - beta_hat, 2) < tol) break;
    beta_hat = beta_debiased;
  }
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue,
    Named("Theta") = Theta
  );
}

#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::plugins(cpp11)]]
using namespace Rcpp;

// Soft-thresholding function
double soft_threshold(double x, double lambda) {
  if (x > lambda) return x - lambda;
  if (x < -lambda) return x + lambda;
  return 0.0;
}

// Optimize principal component vector
arma::vec optimize_beta(const arma::mat& Sigma_hat, arma::vec beta, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  int p = Sigma_hat.n_cols;
  arma::vec beta_old = beta;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    for (int j = 0; j < p; ++j) {
      double partial_residual = -arma::dot(Sigma_hat.row(j).t(), beta) + Sigma_hat(j, j) * beta(j);
      beta(j) = soft_threshold(partial_residual, lambda) / Sigma_hat(j, j);
    }
    // Enforce L1 norm constraint
    if (arma::norm(beta, 1) > T) {
      beta *= T / arma::norm(beta, 1);
    }
    // Convergence check
    if (arma::norm(beta - beta_old, 2) < tol) break;
    beta_old = beta;
  }
  return beta;
}

// Nodewise Lasso function
arma::mat nodewise_lasso(const arma::mat& A, double lambda, double T) {
  int p = A.n_cols;
  arma::mat Theta = arma::zeros<arma::mat>(p, p);
  
  for (int j = 0; j < p; ++j) {
    arma::vec gamma = arma::zeros<arma::vec>(p - 1);
    arma::vec Aj = A.col(j);
    arma::mat A_minus_j = A;
    A_minus_j.shed_col(j);
    
    double error_tolerance = 1e-6;
    arma::vec gamma_old = gamma;
    double error = 1.0;
    int max_iter = 1000;
    int iter = 0;
    
    while (error > error_tolerance && iter < max_iter) {
      for (int k = 0; k < gamma.n_elem; ++k) {
        double partial_residual = Aj(k) - arma::dot(A_minus_j.row(k).t(), gamma);
        gamma(k) = soft_threshold(partial_residual, lambda) / (A_minus_j(k, k) + 1e-10);
      }
      error = arma::norm(gamma - gamma_old, 2);
      gamma_old = gamma;
      iter++;
    }
    Theta.col(j) = -arma::join_cols(gamma.head(j), arma::vec(1, arma::fill::zeros), gamma.tail(p - j - 1));
  }
  return Theta;
}

// Debiased sparse PCA function
List debiased_sparse_pca(const arma::mat& Sigma_hat, const arma::vec& beta_hat, double lambda, double T, const arma::mat& Theta) {
  double beta_hat_norm_sq = arma::dot(beta_hat, beta_hat);
  arma::vec bias_correction = Theta * (beta_hat_norm_sq * beta_hat - Sigma_hat * beta_hat);
  arma::vec beta_debiased = beta_hat - bias_correction;
  
  double eigenvalue = arma::dot(beta_hat, Sigma_hat * beta_hat);
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue
  );
}

// Alternating optimization main function
// [[Rcpp::export]]
List alternating_debiased_sparse_pca(const arma::mat& X, arma::vec beta_hat, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  if (X.n_rows < X.n_cols) {
    stop("Input matrix X should have more rows than columns.");
  }
  
  int p = X.n_cols;
  arma::mat Sigma_hat = X.t() * X / X.n_rows;
  beta_hat = optimize_beta(Sigma_hat, beta_hat, lambda, T);
  arma::mat Theta;
  arma::vec beta_debiased;
  double eigenvalue;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    arma::mat Rn_beta = -Sigma_hat + arma::eye<arma::mat>(p, p) * arma::dot(beta_hat, beta_hat) + 2 * beta_hat * beta_hat.t();
    Theta = nodewise_lasso(Rn_beta, lambda, T);
    
    List pca_result = debiased_sparse_pca(Sigma_hat, beta_hat, lambda, T, Theta);
    beta_debiased = as<arma::vec>(pca_result["beta_debiased"]);
    eigenvalue = as<double>(pca_result["eigenvalue"]);
    
    if (arma::norm(beta_debiased - beta_hat, 2) < tol) break;
    beta_hat = beta_debiased;
  }
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue,
    Named("Theta") = Theta
  );
}

#include <RcppArmadillo.h>
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::plugins(cpp11)]]
using namespace Rcpp;

// Soft-thresholding function
double soft_threshold(double x, double lambda) {
  if (x > lambda) return x - lambda;
  if (x < -lambda) return x + lambda;
  return 0.0;
}

// Optimize principal component vector
arma::vec optimize_beta(const arma::mat& Sigma_hat, arma::vec beta, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  int p = Sigma_hat.n_cols;
  arma::vec beta_old = beta;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    for (int j = 0; j < p; ++j) {
      double partial_residual = -arma::dot(Sigma_hat.row(j).t(), beta) + Sigma_hat(j, j) * beta(j);
      beta(j) = soft_threshold(partial_residual, lambda) / Sigma_hat(j, j);
    }
    // Enforce L1 norm constraint
    if (arma::norm(beta, 1) > T) {
      beta *= T / arma::norm(beta, 1);
    }
    // Convergence check
    if (arma::norm(beta - beta_old, 2) < tol) break;
    beta_old = beta;
  }
  return beta;
}

// Nodewise Lasso function
arma::mat nodewise_lasso(const arma::mat& A, double lambda, double T) {
  int p = A.n_cols;
  arma::mat Theta = arma::zeros<arma::mat>(p, p);
  
  for (int j = 0; j < p; ++j) {
    arma::vec gamma = arma::zeros<arma::vec>(p - 1);
    arma::vec Aj = A.col(j);
    arma::mat A_minus_j = A;
    A_minus_j.shed_col(j);
    
    double error_tolerance = 1e-6;
    arma::vec gamma_old = gamma;
    double error = 1.0;
    int max_iter = 1000;
    int iter = 0;
    
    while (error > error_tolerance && iter < max_iter) {
      for (int k = 0; k < gamma.n_elem; ++k) {
        double partial_residual = Aj(k) - arma::dot(A_minus_j.row(k).t(), gamma);
        gamma(k) = soft_threshold(partial_residual, lambda) / (A_minus_j(k, k) + 1e-10);
      }
      error = arma::norm(gamma - gamma_old, 2);
      gamma_old = gamma;
      iter++;
    }
    Theta.col(j) = -arma::join_cols(gamma.head(j), arma::vec(1, arma::fill::zeros), gamma.tail(p - j - 1));
  }
  return Theta;
}

// Debiased sparse PCA function
List debiased_sparse_pca(const arma::mat& Sigma_hat, const arma::vec& beta_hat, double lambda, double T, const arma::mat& Theta) {
  double beta_hat_norm_sq = arma::dot(beta_hat, beta_hat);
  arma::vec bias_correction = Theta * (beta_hat_norm_sq * beta_hat - Sigma_hat * beta_hat);
  arma::vec beta_debiased = beta_hat - bias_correction;
  
  double eigenvalue = arma::dot(beta_hat, Sigma_hat * beta_hat);
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue
  );
}

// Alternating optimization main function
// [[Rcpp::export]]
List alternating_debiased_sparse_pca(const arma::mat& X, arma::vec beta_hat, double lambda, double T, int max_iter = 100, double tol = 1e-6) {
  if (X.n_rows < X.n_cols) {
    stop("Input matrix X should have more rows than columns.");
  }
  
  int p = X.n_cols;
  arma::mat Sigma_hat = X.t() * X / X.n_rows;
  beta_hat = optimize_beta(Sigma_hat, beta_hat, lambda, T);
  arma::mat Theta;
  arma::vec beta_debiased;
  double eigenvalue;
  
  for (int iter = 0; iter < max_iter; ++iter) {
    arma::mat Rn_beta = -Sigma_hat + arma::eye<arma::mat>(p, p) * arma::dot(beta_hat, beta_hat) + 2 * beta_hat * beta_hat.t();
    Theta = nodewise_lasso(Rn_beta, lambda, T);
    
    List pca_result = debiased_sparse_pca(Sigma_hat, beta_hat, lambda, T, Theta);
    beta_debiased = as<arma::vec>(pca_result["beta_debiased"]);
    eigenvalue = as<double>(pca_result["eigenvalue"]);
    
    if (arma::norm(beta_debiased - beta_hat, 2) < tol) break;
    beta_hat = beta_debiased;
  }
  
  return List::create(
    Named("beta_debiased") = beta_debiased,
    Named("eigenvalue") = eigenvalue,
    Named("Theta") = Theta
  );
}
```
---